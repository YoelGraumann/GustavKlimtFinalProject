{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d10e2c6",
   "metadata": {},
   "source": [
    "# Calculation of Various Diversity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd67a2",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d917ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import decode_predictions\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.nn import functional as F\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245bdf6",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b84e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paths(str1):\n",
    "    path_list = []\n",
    "    for i in range((20)):\n",
    "        current_string = str1.replace(\"$$$\", str(i+1))\n",
    "        path_list.append(current_string)\n",
    "    return path_list\n",
    "\n",
    "# Diversity Score Functions\n",
    "\n",
    "def extract_features(image_paths, model):\n",
    "    features = []\n",
    "    for img_path in image_paths:\n",
    "        img = image.load_img(img_path, target_size=(512, 512))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input(img)\n",
    "        feature = model.predict(img)\n",
    "        feature = feature / np.linalg.norm(feature)\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def calculate_diversity_score(features):\n",
    "    n = len(features)\n",
    "    distances = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            distance = np.linalg.norm(features[i] - features[j])\n",
    "            distances.append(distance)\n",
    "    return np.mean(distances)\n",
    "\n",
    "\n",
    "\n",
    "#### Inception Score Function\n",
    "def calculate_inception_score(images, splits=10):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = img.resize((299, 299))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        processed_images.append(img_array) \n",
    "    processed_images = np.vstack(processed_images)\n",
    "    preds = model.predict(processed_images)\n",
    "    preds = preds / np.linalg.norm(preds)\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        split_preds = preds[(i * len(preds) // splits):((i + 1) * len(preds) // splits)]\n",
    "        p_yx = np.mean(split_preds, axis=0)\n",
    "        kl_div = np.sum(split_preds * (np.log(split_preds + 1e-16) - np.log(p_yx + 1e-16)), axis=1)\n",
    "        scores.append(np.exp(np.mean(kl_div)))\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "\n",
    "#### FID Score Functions\n",
    "\n",
    "\n",
    "def get_activations(images, model, batch_size=32, dims=2048, cuda=False):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch = images[i:i + batch_size]\n",
    "            batch = torch.stack([transform(img) for img in batch])\n",
    "            if cuda:\n",
    "                batch = batch.cuda()\n",
    "            pred = model(batch)\n",
    "            activations.append(pred.cpu().numpy())\n",
    "    activations = np.concatenate(activations, axis=0)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def calculate_fid(real_activations, generated_activations):\n",
    "    mu_r = np.mean(real_activations, axis=0)\n",
    "    sigma_r = np.cov(real_activations, rowvar=False)\n",
    "    mu_g = np.mean(generated_activations, axis=0)\n",
    "    sigma_g = np.cov(generated_activations, rowvar=False)\n",
    "    diff = mu_r - mu_g\n",
    "    covmean, _ = linalg.sqrtm(sigma_r.dot(sigma_g), disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = diff.dot(diff) + np.trace(sigma_r + sigma_g - 2 * covmean)\n",
    "    return fid\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "### Intra-Dataset Similarity (MS-SSIM) Functions\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            image = imread(image_path)\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "def compute_ms_ssim(image1, image2):\n",
    "    image1_gray = rgb2gray(image1)\n",
    "    image2_gray = rgb2gray(image2)\n",
    "    ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n",
    "    return ms_ssim_score\n",
    "\n",
    "def compute_dataset_ms_ssim(images):\n",
    "    n = len(images)\n",
    "    ms_ssim_scores = []\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            score = compute_ms_ssim(images[i], images[j])\n",
    "            ms_ssim_scores.append(score)\n",
    "    return np.mean(ms_ssim_scores)\n",
    "\n",
    "def main(directory_path):\n",
    "    images = load_images_from_directory(directory_path)\n",
    "    avg_ms_ssim = compute_dataset_ms_ssim(images)\n",
    "    print(f'Average MS-SSIM: {avg_ms_ssim}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def calculate_fid_test(real,generated):\n",
    "    inception = models.inception_v3(pretrained=True, transform_input=False)\n",
    "    inception.fc = torch.nn.Identity()\n",
    "    inception.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    real_image_dir = real\n",
    "    generated_image_dir = generated\n",
    "    real_images = load_images_from_folder(real_image_dir)\n",
    "    generated_images = load_images_from_folder(generated_image_dir)\n",
    "    real_activations = get_activations(real_images, inception)\n",
    "    generated_activations = get_activations(generated_images, inception)\n",
    "    fid_value = calculate_fid(real_activations, generated_activations)\n",
    "    print(f\"FID: {fid_value}\") \n",
    "    \n",
    "    \n",
    "def calculate_metrics(str1,str2):\n",
    "    set1 = generate_paths(str1) \n",
    "    image_paths = set1\n",
    "    features = extract_features(image_paths, model)\n",
    "    diversity_score = calculate_diversity_score(features)\n",
    "    print(f'Diversity Score: {diversity_score}')\n",
    "    image_files = set1\n",
    "    images = [Image.open(img_file) for img_file in image_files]\n",
    "    inception_score = calculate_inception_score(images)\n",
    "    print(\"Inception Score:\", inception_score)\n",
    "    main(str2)\n",
    "    \n",
    "    \n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "model = ResNet50(weights='imagenet',include_top=False, pooling='avg', input_shape=(512, 512, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f4ef9",
   "metadata": {},
   "source": [
    "## SDXS Gustav Klimt - euler normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ead3a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "Diversity Score: 0.10013632476329803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Inception Score: 1.0329927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.30589985768552475\n"
     ]
    }
   ],
   "source": [
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - euler normal\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - euler normal\\\\\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a6462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\yoel1\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 347.6374650567194\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - euler normal\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1af88",
   "metadata": {},
   "source": [
    "### SDXS Gustav Klimt - Heun sgm_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d67c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "Diversity Score: 0.08305198699235916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Inception Score: 1.0258796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.3233905285345736\n"
     ]
    }
   ],
   "source": [
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - Heun sgm_uniform\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - Heun sgm_uniform\\\\\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b98ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 359.2462077014194\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 =  \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - Heun sgm_uniform\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a893868",
   "metadata": {},
   "source": [
    "### SDXS Gustav Klimt - sdepp_2m karras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d220556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "Diversity Score: 0.0901665911078453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Inception Score: 1.0289125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.314871693656394\n"
     ]
    }
   ],
   "source": [
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - sdepp_2m karras\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - sdepp_2m karras\\\\\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09afd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 369.7304681773497\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 =  \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDXS Gustav Klimt - sdepp_2m karras\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcd099",
   "metadata": {},
   "source": [
    "### First Batch - SDSX API (colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "266689c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Diversity Score: 0.10282935947179794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Inception Score: 1.0486385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.23105976338181058\n"
     ]
    }
   ],
   "source": [
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDSX API\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDSX API\\\\\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46abb8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 355.4883777112466\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 =  \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\SDSX API\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f732356",
   "metadata": {},
   "source": [
    "### DreamShaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d9930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "Diversity Score: 0.19623003900051117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Inception Score: 1.1376936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.18792125687102046\n"
     ]
    }
   ],
   "source": [
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\\\Dreamshaper Gustav Klimt final\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\\\Dreamshaper Gustav Klimt final\\\\\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0980db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 374.8401933876367\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 =  \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Dreamshaper Gustav Klimt final\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e84443",
   "metadata": {},
   "source": [
    "#### Fusion 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91df2646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "Diversity Score: 0.18728163838386536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Inception Score: 1.1452467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.1350263113736044\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(str1,str2):\n",
    "    set1 = generate_paths(str1) \n",
    "    image_paths = set1\n",
    "    features = extract_features(image_paths, model)\n",
    "    diversity_score = calculate_diversity_score(features)\n",
    "    print(f'Diversity Score: {diversity_score}')\n",
    "    image_files = set1\n",
    "    images = [Image.open(img_file) for img_file in image_files]\n",
    "    inception_score = calculate_inception_score(images)\n",
    "    print(\"Inception Score:\", inception_score)\n",
    "    main(str2)\n",
    "    \n",
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Fusion 1\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Fusion 1\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bb9282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 325.39204176513675\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 =  \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Fusion 1\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1607882",
   "metadata": {},
   "source": [
    "### Fusion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ac2d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Diversity Score: 0.20014441013336182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Inception Score: 1.1394771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoel1\\AppData\\Local\\Temp\\ipykernel_1420\\3593262370.py:110: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ms_ssim_score = ssim(image1_gray, image2_gray, multichannel=False, gaussian_weights=True, use_sample_covariance=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MS-SSIM: 0.15206815821772876\n"
     ]
    }
   ],
   "source": [
    "loc1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Fusion 2\\\\img$$$.png\"\n",
    "loc2 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Fusion 2\"\n",
    "calculate_metrics(loc1,loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825144d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 353.66854102186903\n"
     ]
    }
   ],
   "source": [
    "str1 = \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Gustav Klimt\\\\\"\n",
    "str2 =  \"Y:\\\\Data Science Readings\\\\Advanced Computational Learning and Data Analysis\\\\final project\\\\pictures\\\\Fusion 2\\\\\"\n",
    "calculate_fid_test(str1,str2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
